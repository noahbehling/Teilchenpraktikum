{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "764af80d",
   "metadata": {},
   "source": [
    "Im ersten Schritt werden die Signaldaten als Dataframe eingelesen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2455b8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520f5d57",
   "metadata": {},
   "source": [
    "Alle Monte-Carlo Parameter, also Parameter mit Corsica, Weight oder MC im Namen werden entfernt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55524b76",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 79>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCorsikaWeightMap.SpectrumType\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      2\u001b[0m  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCorsikaWeightMap.TimeScale\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCorsikaWeightMap.AreaSum\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCorsikaWeightMap.Atmosphere\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     76\u001b[0m  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeight.Sa\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     77\u001b[0m  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeight.Astro2\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 79\u001b[0m df_signal \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mdrop(columns, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df_signal = pd.read_csv('data/signal.csv', delimiter=';')\n",
    "\n",
    "columns = ['CorsikaWeightMap.SpectrumType',\n",
    " 'CorsikaWeightMap.TimeScale', 'CorsikaWeightMap.AreaSum',\n",
    " 'CorsikaWeightMap.Atmosphere',\n",
    " 'CorsikaWeightMap.CylinderLength',\n",
    " 'CorsikaWeightMap.CylinderRadius',\n",
    " 'CorsikaWeightMap.DiplopiaWeight',\n",
    " 'CorsikaWeightMap.EnergyPrimaryMax',\n",
    " 'CorsikaWeightMap.EnergyPrimaryMin',\n",
    " 'CorsikaWeightMap.FluxSum',\n",
    " 'CorsikaWeightMap.Multiplicity',\n",
    " 'CorsikaWeightMap.SpectralIndexChange',\n",
    " 'CorsikaWeightMap.Weight', 'I3MCWeightDict.ActiveLengthAfter',\n",
    " 'I3MCWeightDict.ActiveLengthBefore',\n",
    " 'I3MCWeightDict.AutoExtension',\n",
    " 'I3MCWeightDict.EnergyLost',\n",
    " 'I3MCWeightDict.GeneratorVolume',\n",
    " 'I3MCWeightDict.InIceNeutrinoEnergy',\n",
    " 'I3MCWeightDict.InjectionSurfaceR',\n",
    " 'I3MCWeightDict.InteractionColumnDepth',\n",
    " 'I3MCWeightDict.InteractionCrosssection',\n",
    " 'I3MCWeightDict.InteractionType',\n",
    " 'I3MCWeightDict.LengthInVolume',\n",
    " 'I3MCWeightDict.MaxAzimuth', \n",
    " 'I3MCWeightDict.MaxEnergyLog',\n",
    " 'I3MCWeightDict.MaxZenith',\n",
    " 'I3MCWeightDict.MinAzimuth',\n",
    " 'I3MCWeightDict.MinEnergyLog',\n",
    " 'I3MCWeightDict.MinZenith',\n",
    " 'I3MCWeightDict.NeutrinoImpactParameter',\n",
    " 'I3MCWeightDict.OneWeight',\n",
    " 'I3MCWeightDict.PowerLawIndex',\n",
    " 'I3MCWeightDict.PrimaryNeutrinoEnergy',\n",
    " 'I3MCWeightDict.RangeInMeter',\n",
    " 'I3MCWeightDict.RangeInMeterWaterEquiv',\n",
    " 'I3MCWeightDict.TotalColumnDepth',\n",
    " 'I3MCWeightDict.TotalCrosssection',\n",
    " 'I3MCWeightDict.TotalDetectionLength',\n",
    " 'I3MCWeightDict.TotalInteractionProbability',\n",
    " 'I3MCWeightDict.TotalInteractionProbabilityWeight',\n",
    " 'I3MCWeightDict.TotalPropagationProbability',\n",
    " 'I3MCWeightDict.TrueActiveLengthAfter',\n",
    " 'I3MCWeightDict.TrueActiveLengthBefore',\n",
    " 'MCECenter.value',\n",
    " 'MCMostEnergeticInIce.x',\n",
    " 'MCMostEnergeticInIce.y',\n",
    " 'MCMostEnergeticInIce.z',\n",
    " 'MCMostEnergeticInIce.time',\n",
    " 'MCMostEnergeticInIce.zenith',\n",
    " 'MCMostEnergeticInIce.azimuth',\n",
    " 'MCMostEnergeticInIce.energy',\n",
    " 'MCMostEnergeticInIce.length',\n",
    " 'MCMostEnergeticInIce.type',\n",
    " 'MCMostEnergeticInIce.fit_status',\n",
    " 'MCMostEnergeticTrack.x',\n",
    " 'MCMostEnergeticTrack.y',\n",
    " 'MCMostEnergeticTrack.z',\n",
    " 'MCMostEnergeticTrack.time',\n",
    " 'MCMostEnergeticTrack.zenith',\n",
    " 'MCMostEnergeticTrack.azimuth',\n",
    " 'MCMostEnergeticTrack.energy',\n",
    " 'MCMostEnergeticTrack.length',\n",
    " 'MCMostEnergeticTrack.type',\n",
    " 'MCMostEnergeticTrack.fit_status',\n",
    " 'MCPrimary1.x',\n",
    " 'MCPrimary1.y',\n",
    " 'MCPrimary1.z',\n",
    " 'MCPrimary1.time',\n",
    " 'MCPrimary1.zenith',\n",
    " 'MCPrimary1.azimuth',\n",
    " 'MCPrimary1.energy',\n",
    " 'MCPrimary1.length',\n",
    " 'MCPrimary1.type',\n",
    " 'MCPrimary1.fit_status',\n",
    " 'Weight.HoSa',\n",
    " 'Weight.Ho',\n",
    " 'Weight.Sa',\n",
    " 'Weight.Astro2']\n",
    "\n",
    "df_signal.drop(columns, axis = 1, inplace = True)\n",
    "#dfs.columns.values.tolist()\n",
    "# weight, mc und Corsika entfernt\n",
    "\n",
    "#dfs.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160d5a88",
   "metadata": {},
   "source": [
    "Für die Backgrounddaten wird genauso verfahren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4585a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_background = pd.read_csv('data/background.csv', delimiter=';')\n",
    "\n",
    "columns = ['CorsikaWeightMap.AreaSum',\n",
    " 'CorsikaWeightMap.Atmosphere',\n",
    " 'CorsikaWeightMap.CylinderLength',\n",
    " 'CorsikaWeightMap.CylinderRadius',\n",
    " 'CorsikaWeightMap.DiplopiaWeight',\n",
    " 'CorsikaWeightMap.EnergyPrimaryMax',\n",
    " 'CorsikaWeightMap.EnergyPrimaryMin',\n",
    " 'CorsikaWeightMap.FluxSum',\n",
    " 'CorsikaWeightMap.Multiplicity',\n",
    " 'CorsikaWeightMap.ParticleType',\n",
    " 'CorsikaWeightMap.Polygonato',\n",
    " 'CorsikaWeightMap.PrimarySpectralIndex',\n",
    " 'CorsikaWeightMap.TimeScale',\n",
    " 'CorsikaWeightMap.Weight', \n",
    " 'MCECenter.value',\n",
    " 'MCMostEnergeticInIce.x',\n",
    " 'MCMostEnergeticInIce.y',\n",
    " 'MCMostEnergeticInIce.z',\n",
    " 'MCMostEnergeticInIce.time',\n",
    " 'MCMostEnergeticInIce.zenith',\n",
    " 'MCMostEnergeticInIce.azimuth',\n",
    " 'MCMostEnergeticInIce.energy',\n",
    " 'MCMostEnergeticInIce.length',\n",
    " 'MCMostEnergeticInIce.type',\n",
    " 'MCMostEnergeticInIce.fit_status',\n",
    " 'MCPrimary1.x',\n",
    " 'MCPrimary1.y',\n",
    " 'MCPrimary1.z',\n",
    " 'MCPrimary1.time',\n",
    " 'MCPrimary1.zenith',\n",
    " 'MCPrimary1.azimuth',\n",
    " 'MCPrimary1.energy',\n",
    " 'MCPrimary1.length',\n",
    " 'MCPrimary1.type',\n",
    " 'MCPrimary1.fit_status', \n",
    " 'Weight.Ho',\n",
    " 'Weight.Sa',\n",
    " 'Weight.Astro2',\n",
    " 'Weight.HoSa']\n",
    "\n",
    "df_background.drop(columns, axis = 1, inplace = True)\n",
    "#dfb.columns.values.tolist()\n",
    "# weight, mc und Corsika entfernt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfc3ae5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_signal.replace({np.inf : np.nan, -np.inf : np.nan}, value=None, inplace = True)\n",
    "df_background.replace({np.inf : np.nan, -np.inf : np.nan}, value=None, inplace = True)\n",
    "\n",
    "df_signal.dropna(axis=0, how='any', inplace = True)\n",
    "df_background.dropna(axis=0, how='any', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f3f5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_signal.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae286695",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_background.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b0703a",
   "metadata": {},
   "source": [
    "Anschließend wird üerprüft ob es Messungen mit $\\pm \\inf$ als Wert gibt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25afe9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attribute alphybetisch sortieren und vergleichen\n",
    "# oder\n",
    "# mergen und dimensionen vergleichen\n",
    "\n",
    "count = np.isinf(df_signal).values.sum()\n",
    "print(\"Signal contains \" + str(count) + \" infinite values\")\n",
    "\n",
    "count = np.isinf(df_background).values.sum()\n",
    "print(\"Background contains \" + str(count) + \" infinite values\")\n",
    "# NaN and Inf removed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7facae8b",
   "metadata": {},
   "source": [
    "Es wird überprüft ob signal und background die gleichen Attribute haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913c9393",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_signal = df_signal.columns\n",
    "col_background = df_background.columns\n",
    "set(col_signal) == set(col_background)\n",
    "# if true sets contain same items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f923c3",
   "metadata": {},
   "source": [
    "Da dies der Fall ist werden die Daten in einen Dataframe geschrieben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5330e222",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# nächstes sets joinen und attributselektion\n",
    "data = [df_signal, df_background]\n",
    "df = pd.concat(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc48eec",
   "metadata": {},
   "source": [
    "Jetzt kommt der Teil mit den Machine learning..\n",
    "Der erste Schritt ist es ein Test- und Trainingsset zu erstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4ac9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "Y = df['label']\n",
    "X = df.drop('label', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1770ec7",
   "metadata": {},
   "source": [
    "test_size: Anteil der Daten welche ins Testset kommen <br>\n",
    "random_state: Seed für das Mischen für Reproduzierbarkeit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4316db0f",
   "metadata": {},
   "source": [
    "Nun zu feature-selection <br> \n",
    "Zuerst wird mitden KNeighborsClassifier getestet wie viele Features da besste Ergebnis bringen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf164b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score, roc_curve, precision_score, accuracy_score, jaccard_score\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669e356a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_feat = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100]\n",
    "# Anzahlen von Features welche getestet werden\n",
    "nn = 20\n",
    "# Nachbarn fuer classifier\n",
    "\n",
    "jac = []\n",
    "# array in welchen jaccard index jeweils gespeichert wird\n",
    "\n",
    "Number=1\n",
    "# Parameter zum Zählen der Iterationen\n",
    "\n",
    "# jetzt die Schleife\n",
    "for feat in N_feat:\n",
    "    X_new = SelectKBest(score_func=f_classif, k=feat)\n",
    "    # erstellt die Instanz zum wählen der feat bessten?\n",
    "    \n",
    "    d_fit = X_new.fit(X_train, y_train)\n",
    "    # algorithmus wird trainiert?/ Features bewertet\n",
    "    \n",
    "    scores = d_fit.scores_\n",
    "    print(scores)\n",
    "    # array-like of shape (n_features,)Scores of features.\n",
    "    \n",
    "    sorted_scores = sorted(scores, reverse=True)\n",
    "    # sortiert array von größten zu kleinsten Wert\n",
    "    \n",
    "    args_max = np.argsort(scores)[::-1]\n",
    "    print(args_max)\n",
    "    # argsort erstellt einen array der Indizes sodass scores sortiert waere\n",
    "    # [::-1] gibt den array rückwärts zurück\n",
    "    # -> Index des höchsten scores\n",
    "    \n",
    "    features = []\n",
    "    # array um wichtige features abzuspeichern\n",
    "    \n",
    "    for i in range(feat):\n",
    "        features.append(X.columns.tolist()[args_max[i]])\n",
    "    print(features)\n",
    "    # es werden die Features mit den höchsten scores in features geschrieben\n",
    "    \n",
    "    X_train_sclief = X_train.loc[:, features]\n",
    "    X_test_sclief = X_test.loc[:, features]\n",
    "    # die unwichtigen Features werden aus den trainings- und Testdaten gelöscht\n",
    "    \n",
    "    knn_clf = KNeighborsClassifier(n_neighbors=nn)\n",
    "    # erstelle KNeighbors Instanz\n",
    "    \n",
    "    knn_clf.fit(X_train_sclief, y_train)\n",
    "    # trainiere mit Treiningsdaten\n",
    "    \n",
    "    PRED_knn = knn_clf.predict_proba(X_test_sclief)\n",
    "    # sagt Wahrscheinlichkeit der Testdaten vorher\n",
    "    \n",
    "    PRED_knn = PRED_knn[:, 1]\n",
    "    # array zu Vektor?\n",
    "    \n",
    "    fpr2, tpr2, thr2 = roc_curve(y_test, PRED_knn)\n",
    "    # ermittel true positive rate, false positive rate und threshholt?\n",
    "    # wird nicht verwendet\n",
    "    \n",
    "    knn_precision = precision_score(np.array(y_test), knn_clf.predict(X_test_sclief))\n",
    "    # berechnet Praezision\n",
    "    \n",
    "    knn_eff = accuracy_score(np.array(y_test), knn_clf.predict(X_test_sclief))\n",
    "    # berechnet Genauigkeit\n",
    "    \n",
    "    print('KNN accuracy score(sklearn) = ', knn_eff)\n",
    "    print('KNN precision score(sklearn) = ', knn_precision)\n",
    "    # gibt die scores aus\n",
    "    \n",
    "    knn_Jscore = jaccard_score(np.array(y_test), knn_clf.predict(X_test_sclief))\n",
    "    jac.append(knn_Jscore)\n",
    "    # berechne den jaccard score und speicher ihn ab\n",
    "    \n",
    "    print(\"Number \", Number, \" done\")\n",
    "    Number=Number+1\n",
    "    # gib die Durchlaufnummer aus etc\n",
    "    \n",
    "jac_max = max(jac)\n",
    "jac_maxpos = jac.index(jac_max)\n",
    "# ermttel die Stelle mit den höchsten jaccard index\n",
    "\n",
    "print(jac)\n",
    "print(jac_max)\n",
    "print(jac_maxpos)\n",
    "print(N_feat[jac_maxpos])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
